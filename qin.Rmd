---
title: "Qin scores & history"
description: |
  also a prelude in Python
output: distill::distill_article
---
Objective - read in a webpage, find elements (score/song name, explanatory link) and create a dictionary.  
The impressive source: http://silkqin.com/zh02qnpu.htm  

# Scrapping source
1.extracting and renaming files  
2.Correctly obtaining encoded characters - since the webpage contains Chinese characters, need to ensure they are captured properly 
  
Detour INSIDE BASH (not Python)  
pip install chardet  
chardetect *html #(after navigating to the correct directory, saving html file)  
confirmed to be utf-8  
https://pypi.org/project/chardet/  
Refer to -- https://stackoverflow.com/questions/31027759/how-to-scrape-traditional-chinese-text-with-beautifulsoup

```{python, eval=FALSE,echo=TRUE}
import requests
url = 'http://silkqin.com/zh06hear.htm'
response = requests.get(url)
page_content = requests.get(url).content  # returns bytes <- this extra step allows detection for special (e.g. Chinese characters)
from bs4 import BeautifulSoup
soup = BeautifulSoup(page_content, 'lxml')
#check how it looks
soup.contents
```

Results in:
titleè½çµ²å¼¦å¤ç´title  
meta content="text/html; charset=utf-8" http-equiv="content-type"  
meta content="è½çµ²å¼¦å¤ç´" name="description"  meta content="ç´ã€å¤ç´ã€è½ç´ã€è½å¤ç´ã€è½çµ²å¼¦ç´ã€è½çµ²å¼¦å¤ç´ã€çµ²å¼¦ã€çµ²çµƒã€çµ²ç·šã€ä¸å¼¦ã€çµ²çµƒç´ã€çµ²å¼¦ç´ã€çµ²ç·šç´ã€çµ²å¼¦å¤ç´ã€çµ²çµƒå¤ç´ã€çµ²ç·šå¤ç´ã€çµ²æ¡ã€å”ä¸–ç’‹ã€John Thompson" name="keywords"  
 
From looking into the text, tre is only a loose pattern - in the location,sually "Anoottion (Rfollowed by Recording 
F  
r example, in å—é¢¨æ­Œ ï¼ˆè½), the annotation page and recording are adjacent to each other and the naming is consistent.  
http://silkqin.com/02qnpu/10tgyy/tg01nfg.htm  http://silkqin.com/06hear/myrec/1511/tg01nfg.mp3  
But sometimes, the naming is not consistent, for example in å¢¨å­æ‚²æ­Œ (è½ï¼‰  
http://silkqin.com/02qnpu/32zczz/mozibei.htm http://silkqin.com/06hear/myrec/1589-1609/1609mozibeige.mp3  
And certain annotations are shorter and exists as excerpts within a page collection; no consistency in file name either, e.g. å¤ªç°‡æ„ ï¼ˆè½ï¼‰  
http://silkqin.com/02qnpu/07sqmp/sq01dsc.htm#taicouyifn http://silkqin.com/06hear/myrec/1525/xl101tcy102dhy.mp3  
    here is one consistent pattern though - all annotation pages seem to be under "02qnpu" directory.    

````{python, eval=FALSE,echo=TRUE}
import re
from urllib.request import urlretrieve
from urllib.request import urlopen

html = urlopen('http://silkqin.com')
baseurl='http://silkqin.com/'
#The 'a' tag in the html does not have any text directly, but it contains a 'h3' tag that has text. 
all_links = [link.get("href") for link in soup("a")]
all_links
#get rid of none otherwise sub lists generated gives None type error
#to read on None type - https://stackoverflow.com/questions/3887381/typeerror-nonetype-object-is-not-iterable-in-python
clean = [x for x in all_links if x is not None]
# now filter for that directory
links_htm = [k for k in clean if 'htm' in k and '02qnpu' in k] 
#and 'htm#' not in k]#and '\#' not in k and '\~' not in k]
```
  
There were 164 scores listed,not 234 that results from checking length of this list.  

This is likely due to the presence of lyrics being separate links, but not filter-out-able since they live in the same '02qnpu' subdirectory  
e.g. æ¸…å•†èª¿ ï¼ˆè½ï¼‰ï¼ˆçœ‹ä¸­æ–‡æ­Œè©ï¼‰ 
http://silkqin.com/02qnpu/32zczz/daoyi.htm#qsdfn   http://silkqin.com/06hear/myrec/1589-1609/1609qsdge.mp3   http://silkqin.com/02qnpu/32zczz/daoyi.htm#qsdlyr  
Let's grab them all for now, knowing some are just subsections of pages (e.g. #qsdfn above) and some are lyrics

```{python, eval=FALSE,echo=TRUE}
#note-- don't reuse counter alink fromprevious= -> cannot force it into an integer as it becomes a list element of thelist in the for loop
#trying to use it as a counter yields TypeError: list indices must be integers or slices, not str
counter = 0
for alink in links_htm:
    urlretrieve((baseurl + links_htm[counter]), (links_htm[counter].rsplit('/', 1)[-1]))
    #the split takes all characters after last slash
    #regex way -- re.sub(r'^.+/([^/]+)$', r'\1', 'dsf/we/sdfl.htm')
    #more https://stackoverflow.com/questions/7253803/how-to-get-everything-after-last-slash-in-a-url
    counter += 1
```
  
Result is an error message "NameError: name 'links_htm' is not defined"

What happened?  Checking the directory, there are 210 of these annotation (and lyrics) html files downloaded.  
Let's collect the downloaded ones (anything with htm) using glob below, and compare against the annotation links list.  
Since the glob collection has no subdirectory/nesting (besides the # page bookmarks), let's strip those from the links list as well  

```{python, eval=FALSE,echo=TRUE}
import glob
downloadedhtmfiles = []
for file in glob.glob("*.htm"):
    downloadedhtmfiles.append(file)

links_htm_temp=list(range(0,len(links_htm)))  # there will be error otherwise if list is not intialized, since we don't use append below
counter = 0
for alink in links_htm:
    links_htm_temp[counter] = re.sub(r'^.+/([^/]+)$', r'\1', links_htm[counter])
    #the split takes all characters after last slash
    #regex way -- re.sub(r'^.+/([^/]+)$', r'\1', 'dsf/we/sdfl.htm')
    #more https://stackoverflow.com/questions/7253803/how-to-get-everything-after-last-slash-in-a-url
    counter += 1
#links_htm_temp[0]

def Diff(li1, li2): 
    return (list(set(li1) - set(li2)))  
print(Diff(links_htm_temp, downloadedhtmfiles))
```

Output:  
    ['tg06gjq.htm#lyrchi', 'xl127ysc.htm#jzymusic', 'lh00toc.htm#p5', 'tingqinyin.htm#melody', 'daoyi.htm#qsdfn', 'yqwd.htm', 'xl028yyg.htm#chilyr', 'tg32cjq.htm#1525cjwt', 'xl132src.htm#linzhong', 'jiukuang.htm#chilyr', 'tg36kcyh.htm#music', '03slgj.htm#kzhyy', 'tg01nfg.htm#lyrics', 'hw02qpy.htm', 'xl096yts.htm#lyrics', 'xl127ysc.htm#ysymusic', 'xl054cwy.htm#mjyfn', '27wjctrans.htm#record', '1709qfq.htm#1840muslyr', 'tg28frsg.htm#chilyr', 'daoyi.htm#lyrchi', 'tg10ysc.htm#chilyr', 'xl054cwy.htm#jy', 'qx14wywq.htm', 'tg32cjq.htm#clyrics', 'xl000toc.htm#p16', 'xl021fl.htm#feidianyinfn', 'fm23ygsd.htm#chilyr', 'xl098byd.htm#chilyrfn', 'cx38xsq.htm#lyrics', 'tg24hzd.htm#chilyr', 'zy13ygsd.htm#v1', 'fx33gg.htm#lyricsfn', 'fx42zwy.htm#chilyr', 'sq01dsc.htm#dinghuiyinfn', 'xl046yz.htm#1530', '1709qfq.htm#1709muslyr', 'tg02sqc.htm#lyrics', 'daoyi.htm#qsdlyr', 'tg03xfy.htm#chilyr', 'sj03qjj.htm#chilyr', 'hw15fhts.htm', 'fx40dmyt.htm#chilyr', 'tg09wwq.htm#muslyr', 'tg32cjq.htm#1539cj', 'ty28skj.htm', 'lq12mss.htm', 'fm03qjwd.htm#chilyr', 'fx27wjc.htm#chilyr', 'xl041jyb.htm#qingyeyin', 'qx09lhxx.htm', 'ty28skj.htm#skjmp3', 'ylcx.htm#cgyfn', 'xl041jyb.htm#chilyr', 'yltrans.htm', 'fx32dyq.htm#chilyr', 'sq01dsc.htm#taicouyifn', 'tg16ysc.htm#chilyr', 'ylcx.htm#ylcxmusic', 'xl159qxb.htm#byyfn', 'sq18ghy.htm#daguanyinfn', 'fx45gjx.htm#xllyrfn', 'jiukuang.htm#lyrics', '03slgj.htm#gd', 'fx31lsm.htm#chilyr', 'tg08ksc.htm#lyrics', 'ty6qcby.htm#gy', 'tg07wwc.htm#music', 'xl046yz.htm#chilyr', 'xl007gky.htm#chongheyinfn', 'xl159qxb.htm#qyyfn', 'xl155fqh.htm#chilyr', 'tg25gqlc.htm#chilyr', 'tg35gqf.htm#chilyr', 'sz03olwj.htm']
    
# A dictionary to cross-reference

## Playing with Regex and making the first pairing for dict

take all htm, strip out #...
match blurb.htm"> and </a>
First let's reset the links list in case of any accidental changes before

```{python, eval=FALSE,echo=TRUE}
#repeat of above code (in case run from this segment)
# Find links
all_links = [link.get("href") for link in soup("a")]
all_links
clean = [x for x in all_links if x is not None]
#links_htm = [k for k in clean if 'htm' in k and '02qnpu' in k and 'htm#' not in k]#and '\#' not in k and '\~' not in k]
#links_htm = [k for k in links_htm if '02qnpu' in k]
links_htm = [k for k in clean if 'htm' in k and '02qnpu' in k]

links_htm_clean=links_htm # if I reassign below directly in re.sub, it seems to overwrite the original as well
links_htm_clean[1] = re.sub(r'.*\/', r'', links_htm_clean[1]) #pat1.*pat2	any number of characters between pat1 and pat2
links_htm_clean[1] = re.sub(r'\#.*', r'', links_htm_clean[1]) 
print(links_htm_clean[1]) 
print(links_htm[3])
len(links_htm_clean)
```

Results:  
yltrans.htm
02qnpu/03slgj.htm
234



```{python, eval=FALSE,echo=TRUE}
#throwing the tested element into a loop
# links_htm = [k for k in clean if 'htm' in k and '02qnpu' in k]
# gets rid of slashes and anything preceding slash
links_htm_clean=links_htm
counter=0
for elem in links_htm_clean:
    links_htm_clean[counter] = re.sub(r'.*\/', r'', links_htm_clean[counter]) #pat1.*pat2	any number of characters between pat1 and pat2
#    links_htm_clean[counter] = re.sub(r'\#.*', r'', links_htm_clean[counter]) # works but don't want to remove the # bc sometime that signifies diff song 
#    print(links_htm_clean[counter]) 
    counter +=1
links_htm_clean[1] = re.sub(r'\#.*', r'', links_htm_clean[1]) 
print(links_htm_clean[1]) 
print(links_htm[3])
len(links_htm_clean)
```
yltrans.htm
03slgj.htm
234

The annotation, recording and song name patterns are generally:
\<a href="http://silkqin.com/02qnpu/16xltq/xl154lqy.htm">è‡¨é‚›åŸ\</a>
\<a href="http://silkqin.com/06hear/myrec/1525/xl154lqy.mp3">è½\</a>ï¼‰\</li>
which means we are looking as song name, the text between *xl154lqy.htm"> & *\</a>
\<a href="http://silkqin.com/06hear/myrec/1525/xl154lqy.mp3"
* 
Let's play with splitting this string, called astring


```{python, eval=FALSE,echo=TRUE}
# Variation 1 - cluster annotation / song name+record link
astring='<a href="http://silkqin.com/02qnpu/03slgj.htm#kzhyy">é–‹æŒ‡é»ƒé¶¯åŸ</a>ï¼ˆ<a href="http://silkqin.com/06hear/myrec/01tangsong/00kzhyy.mp3">è½</a>'
#m=re.split('(.htm\S+?>)',astring) 
m=re.split('.htm\S+?>',astring)  #cuts by end of first '>' for a list of two being the ahref annotation link, then song name & recording link
n=re.sub('(.mp3)\S+','',astring) #cuts everything from the '.mp3' onward to get rid of è½</a>']
#\S = a non whitespace chara,
#+ multipe \S but add ? for as few as possible
#() keeps the separator within result
print(m)
print(n) 
```


'<a href="http://silkqin.com/02qnpu/03slgj', 'é–‹æŒ‡é»ƒé¶¯åŸ</a>ï¼ˆ<a href="http://silkqin.com/06hear/myrec/01tangsong/00kzhyy.mp3">è½</a>'
<a href="http://silkqin.com/02qnpu/03slgj.htm#kzhyy">é–‹æŒ‡é»ƒé¶¯åŸ</a>ï¼ˆ<a href="http://silkqin.com/06hear/myrec/01tangsong/00kzhyy
    


```{python, eval=FALSE,echo=TRUE}
# Variation 2 - cluster annotation+song name / record link
astring='<a href="http://silkqin.com/02qnpu/03slgj.htm#kzhyy">é–‹æŒ‡é»ƒé¶¯åŸ</a>ï¼ˆ<a href="http://silkqin.com/06hear/myrec/01tangsong/00kzhyy.mp3">è½</a>'
#m=re.split('(.htm\S+?>)',astring) 
m=re.split('</a>ï¼ˆ<a href="',astring) 
n=re.sub('(.mp3)\S+','',astring)
print(m) #a list of two
print(n)
```

'<a href="http://silkqin.com/02qnpu/03slgj.htm#kzhyy">é–‹æŒ‡é»ƒé¶¯åŸ', 'http://silkqin.com/06hear/myrec/01tangsong/00kzhyy.mp3">è½</a>']
    <a href="http://silkqin.com/02qnpu/03slgj.htm#kzhyy">é–‹æŒ‡é»ƒé¶¯åŸ</a>ï¼ˆ<a href="http://silkqin.com/06hear/myrec/01tangsong/00kzhyy
    

Continuing with variation 2, let's regex out the typical patterns surrounding the song name.  

```{python, eval=FALSE,echo=TRUE}
# Song Name: 
o=re.sub(r'.*\/', r'', m[0]) #first extract everything after the last / in the first element -> '03slgj.htm#kzhyy">é–‹æŒ‡é»ƒé¶¯åŸ'
p=re.split(r'\">', o) # then split by the "> pattern between annotation link and song name ->['03slgj.htm#kzhyy', 'é–‹æŒ‡é»ƒé¶¯åŸ']
p[1] #the second element yields song name
```

'é–‹æŒ‡é»ƒé¶¯åŸ'

p[0] # annotations

'03slgj.htm#kzhyy'


## Build the dictionary

Recall how to set up a dictionary.  Then fit in song name and file name extracted above (and hope the pattern holds)

RecCatalogue={}
RecCatalogue={p[1]:r.group(0)}
RecCatalogue


```{python, eval=FALSE,echo=TRUE}
#print the soup as string text for use 
Ssoup=str(soup)
print(Ssoup,  file=open('Ssoup.txt', 'w',encoding='utf-8-sig'))
#for song titles,extract from the mass of text in SSoup file
#sub-example "<br/><a href="06hear/myrec/1491/zy08ygd.mp3"><b>è½æ¼æ­Œèª¿</b></a>"
counter=0
sep=[i for i in links_rec if i in Ssoup]
for elem in sep:
    sep = [i for i in links_rec if i in Ssoup]
    lsep=len(sep[counter]) #length of the recording file name
    idx = Ssoup.find(sep[counter]) #note where the recordingfile name is in the Ssoup string
    _idx=idx-lsep #set starting index back the length of recording file name
    TitleName[counter]=(Ssoup[_idx:idx-12])
    TitleName[counter]=TitleName[counter].split(sep=">",maxsplit=1)[1] # cut everything before <b> which precedes title
    TitleName[counter]=TitleName[counter].split(sep="</",maxsplit=1)[0] # cut everything behind </b> which follows title, keeping first element (Title)
    counter+=1
```

Check if we obtained the name  
TitleName[19]
    'å»£å¯’ç§‹'


```{python, eval=FALSE,echo=TRUE}
#piecemeal testing looking for explanation htm files which just precede song titles
teststr="<a href=\"balshblahs<a href=\"http://silkqin.com/02qnpu/32zczz/tingqinyin.htm\">è½ç´åŸ</a>"
teststr
idx = Ssoup.find("å¤é¢¨æ“")
idx
```
5347

```{python, eval=FALSE,echo=TRUE}
idx_ = Ssoup[idx-180:idx].rfind('<a href=\"') #reverse find looks forward, so set it some number back from index
print(Ssoup[idx-180+idx_:idx])
```
<a href="02qnpu/07sqmp/sq04gfc.htm">
    

```{python, eval=FALSE,echo=TRUE}
o=re.sub(r'.*\/', r'', teststr)
o
```
'tingqinyin.htm'

```{python, eval=FALSE,echo=TRUE}
# trying this in the text string Ssoup 
idx = Ssoup.find(elem) #note where the file name is in the Ssoup string #'ç§‹é¢¨è¾­'
idx_ = Ssoup[idx-50:idx].rfind('<a href=\"') 
idx_=idx-50+idx_
idx_
Ssoup[idx_:idx]
teststr=Ssoup[idx_+9:idx-2]
teststr=re.sub(r'.*\/', r'', teststr)
teststr
```

'ylcx.htm#cgyfn'

Readying for loop by setting up htm list "explan" and cutting out first element which is a blank for some reason

```{python, eval=FALSE,echo=TRUE}
TitleName=TitleName[1:]
explan=TitleName
#alternatively extract title names from previously compiled dictionary:RecCatalogue.keys()
```

## looping this search

```{python, eval=FALSE,echo=TRUE}
#example "<br/>"<a href=\"http://silkqin.com/02qnpu/32zczz/tingqinyin.htm\">è½ç´åŸ</a>"
teststr="blob"
#remSsoup=Ssoup
sep = [i for i in TitleName if i in Ssoup]
counter=0
for elem in sep:
    sep = [i for i in TitleName if i in Ssoup]
    idx = Ssoup.find(elem) #find where songtitle is
    idx_ = Ssoup[idx-50:idx].rfind('<a href=\"') #then skip 50 characters back and look for match of a href link with highest index (closest to song title)
    idx_=idx-50+idx_
    teststr=Ssoup[idx_+9:idx-2] #cut out the a href frames brackets
    explan[counter]=re.sub(r'.*\/', r'', teststr) # get rid of everything before last slash in htm link
    counter+=1
explan
```

# Outputt explanatory htm's bby song


```pyt```{python, eval=FALSE,include=TRUE}
#HtmCatalogue=dict(zip(TitleName, explan))
HtmCatalogue
```
hSuccessful output: çèª¿å¹½è˜­': 'yltrans.htm#music',
     'ç™½çŸ³é“äººæ­Œæ›²å¤æ€¨': '02gy.htm',
     'é–‹æŒ‡é»ƒé¶¯åŸ': '03slgj.htm#kzhyy',
     'é¯ä¸–æ“': 'sq01dsc.htm',
     'è¯èƒ¥å¼•': 'sq03hxy.htm',
     'å¤é¢¨æ“': 'sq04gfc.htm',
     'æµæ°´': 'sq06ls.htm',
     'æ‹›éš±': 'sq09zy.htm',
     'é…’ç‹‚': 'sq10jk.htm',
     'æ­Œè¾­': 'jiukuang.htm#chilyr',
     'ç²éºŸ': 'sq11hl.htm',
     'çetc.`pon
{python, eval=FALSE,include=TRUE}
with open('explan.txt', 'w',encoding='utf-8-sig') as f:
    print(HtmCatalogue, file=f)
```
`but text/csv file is difficult to convert, better as json
```{python eval=FALSE, include=FALSE}
import json
data = json.dumps(HtmCatalogue)
with open("explan.json","w") as f:
  f.write(data)
```
hBackwards test --gg the JSON to dictionay
HtmCata"logue = json.loads(data)
HtmCat"aª¿å¹½è˜­': 'yltrans.htm#music',
     'ç™½çŸ³é“äººæ­Œæ›²å¤æ€¨': '02gy.htm',
     'é–‹æŒ‡é»ƒé¶¯åŸ': '03slgj.htm#kzhyy',
     'é¯ä¸–æ“': 'sq01dsc.htm',
     'è¯èƒ¥å¼•': 'sq03hxy.htm',
     'å¤é¢¨æ“': 'sq04gfc.htm',
     'æµæ°´': 'sq06ls.htm',
     'æ‹›éš±': 'sq09zy.htm',
     'é…’ç‹‚': 'sq10jk.htm',
     'æ­Œè¾­': 'jiukuang.htm#chilyr',
     'ç²éºŸ': 'sq11hl.htm',
     'ç§‹æœˆæ˜­èŒ…äº­': 'sq13qyzm.htm',
     'å±±ä¸­æ€å‹äºº': 'sq14szsy.htm',
     'å»£å¯’éŠ': 'sq18ghy.htm',
     'ç¥å“å•†æ„': 'sq20spsy.htm',
     'ç¥å“å¤å•†æ„': 'sq21spgs.htm',
     'éš±å¾·': 'sq24yd.htm',
     'å»£å¯’ç§‹': 'sq25ghq.htm',
     'é¶´é³´ä¹çš‹': 'sq31hmjg.htm',
     'çŒ—è˜­': 'sq32yl.htm',
     'é›‰æœé£›': 'sq42zzf.htm',
     'çƒå¤œå•¼': 'sq43wyt.htm',
     'æ³›æ»„æµª': 'sq52fcl.htm',
     'ç€Ÿæ¹˜æ°´é›²': 'sq53xxsy.htm',
     'æ¾¤ç•”åŸ': 'sq56zpy.htm',
     'é›¢é¨·': 'sq57ls.htm',
     'èŠå‘¨å¤¢è¶': 'sq60zzmd.htm',
     'æ¥šæ­Œ': 'sq61cg.htm',
     'é—œé›': 'zy01gj.htm',
     'é™½é—œä¸‰ç–Š': 'zy13ygsd.htm',
     'èª¿çµƒå“': 'xl001txp.htm',
     'å®®æ„': 'xl002gy.htm',
     'ä¿®ç¦ŠåŸ': 'xl003xxy.htm',
     'é™½æ˜¥': 'xl004yc.htm',
     'åº·è¡¢è¬ ': 'xl005kqy.htm',
     'å†²å’ŒåŸ': 'xl007gky.htm#chongheyinfn',
     'è°·å£å¼•': 'xl007gky.htm',
     'åœ¯æ©‹é€²å±¥': 'xl008yqj.htm',
     'é”è§€åŸ': 'sq18ghy.htm#daguanyinfn',
     'æµè§´': 'xl012ls.htm',
     'å¹½è˜­': 'a> ï¼ˆåŒ…',
     'å•†æ„': 'sq20spsy.htm">',
     'é£›é›»åŸ': 'xl021fl.htm#feidianyinfn',
     'é¢¨é›·': 'xl021fl.htm',
     'å‰¡ç§»æ­Œ': 'xl028yyg.htm',
     'æ‡·å¤åŸ': 'xl032hgy.htm',
     'æå£‡': 'xl034xt.htm',
     'æ¸…å¤œåŸ': 'xl041jyb.htm#qingyeyin',
     'æ±Ÿæœˆç™½': 'xl041jyb.htm',
     'ç§‹é¢¨': 'xl043qf.htm',
     'é›ªçª—å¤œè©±': 'xl042xcy.htm',
     'æ˜¥æ±Ÿæ™šçœº': 'tg32cjq.htm#1525cjwt',
     'æ¢…æ¢¢æœˆ': 'xl048msy.htm',
     'è§’æ„': 'xl054cwy.htm#jy',
     'è’™æ£˜å¼•': 'xl054cwy.htm#mjyfn',
     'è’¼æ¢§æ€¨': 'xl054cwy.htm',
     'åˆ—å¥³å¼•': 'xl063lny.htm',
     'æ¡çœŸéŠ': 'xl064czy.htm',
     'çŸ³ä¸Šæµæ³‰': 'xl075ssl.htm',
     'æ´åº­ç§‹æ€': 'xl076dtq.htm',
     'é†‰æ¼å”±æ™š': 'xl077zyc.htm',
     'æ¼æ­Œ': 'zy08ygd.mp3"><b',
     'ç‰æ¨¹è‡¨é¢¨': 'xl087ysl.htm',
     'æ˜¥æ›‰åŸ': 'xl089cxy.htm',
     'é¶´èˆæ´å¤©': 'xl091hwd.htm',
     'ç‘¤å¤©ç¬™é¶´': 'xl096yts.htm',
     'æ˜¥æ€': 'xl097cs.htm',
     'ä¼¯ç‰™å¼”å­æœŸ': 'xl098byd.htm',
     'é»ƒé˜æ„': 'xl099hzy.htm',
     'æé™µæ€æ¼¢': 'xl100lls.htm',
     'å¤ªç°‡æ„': 'sq01dsc.htm#taicouyifn',
     'å¤·å‰‡æ„': 'xl113yzy.htm',
     'è™•æ³°åŸ': 'xl114cty.htm',
     'é éŠ': 'xl115yy.htm',
     'æ†¶é—œå±±': 'xl120ygs.htm',
     'æ¼¢å®®ç§‹': 'xl121hgq.htm',
     'å¤§å‘‚æ„': 'xl122dly.htm',
     'å´†å³’å¼•': 'xl123kty.htm',
     'å´†å³’å•é“': 'xl124ktw.htm',
     'å¤¾é¾æ„': 'xl127ysc.htm#jzymusic',
     'è¶Šè£³åŸ': 'xl127ysc.htm#ysymusic',
     'è¶Šè£³æ“': 'xl127ysc.htm',
     'æ—é˜æ„': 'xl132src.htm#linzhong',
     'ç¥äººæš¢': 'xl132src.htm',
     'æ‡‰é˜æ„': 'xl136yzy.htm',
     'æ¼¢ç¯€æ“': 'xl137hjc.htm',
     'å®‹ç‰æ‚²ç§‹': 'xl148syb.htm',
     'ç„¡åª’æ„': 'xl153wmy.htm',
     'è‡¨é‚›åŸ': 'xl154lqy.htm',
     'é³³æ±‚å‡°': 'xl155fqh.htm',
     'å­¤é¤¨é‡ç¥': 'xl156ggy.htm',
     'ç¢§ç‰æ„': 'xl159qxb.htm#byyfn',
     'ç‰å¥³æ„': 'xl160yny.htm',
     'æ¸…ç¾½æ„': 'xl168qyy.htm',
     'æ¡ƒæºæ˜¥æ›‰': 'xl169tyc.htm',
     'ä¸€æ’’é‡‘': 'fx07ysj.htm',
     'æ–‡å›æ“': 'fx27wjc.htm',
     'ç”²': 'fx27wjcfr.mp3',
     'é™‹å®¤éŠ˜': 'fx31lsm.htm',
     'æ—è¡£æ›²': 'fx32dyq.htm',
     'æ­¸è€•': 'fx33gg.htm',
     'å¤§æ˜ä¸€çµ±': 'fx40dmyt.htm',
     'é†‰ç¿åŸ': 'fx42zwy.htm',
     'é¢¨é›·å¼•': 'fx43fly.htm',
     'å¤äº¤è¡Œ': 'fx45gjx.htm',
     'æ˜¥æ±Ÿ': 'xl023cj.htm',
     'æ…¨å¤': 'fx49kg.htm',
     'é›éè¡¡é™½': 'fx65yghy.htm',
     'æ¸­æ¿±åŸ': 'fx67wby.htm',
     'ä½©è˜­': 'fx73pl.htm',
     'å¯„æƒ…æ“': 'fx89jqc.htm',
     'å—é¢¨æ­Œ': 'tg01nfg.htm',
     'æ€è¦ªæ“': 'tg02sqc.htm',
     'æ¹˜å¦ƒæ€¨': 'tg03xfy.htm',
     'é—œé›æ›²': 'tg06gjq.htm',
     'æ–‡ç‹æ“': 'tg07wwc.htm',
     'æ–‡ç‹æ›²': 'tg09wwq.htm',
     'äºè–æ“': 'tg16ysc.htm',
     'é»ƒé˜èª¿': 'tg24hzd.htm',
     'æ­¸å»ä¾†è¾­': 'tg25gqlc.htm',
     'é¢¨å…¥æ¾æ­Œ': 'tg28frsg.htm',
     'æ˜¥æ±Ÿæ›²': 'tg32cjq.htm',
     'å¤ç§‹é¢¨': 'tg35gqf.htm',
     'å®¢çª—å¤œè©±': 'tg36kcyh.htm',
     'ç§‹æ±Ÿæ™šé‡£': 'fm03qjwd.htm',
     'åå…«å­¸å£«ç™»ç€›æ´²': 'xl046yz.htm#1530',
     'æ°´ä»™æ›²': 'wy18sxq.htm',
     'éœè§€åŸ': 'wy08jgy.htm',
     'æ°´é¾åŸ': 'yw27sly.htm',
     'å¢¨å­æ‚²æ­Œ': 'mozibei.htm',
     'æ—è¡£': 'fx32dyq.htm',
     'è½ç´åŸ': 'tingqinyin.htm',
     'æ¸…å•†èª¿': 'daoyi.htm#qsdfn',
     'å­”è–ç¶“': 'sj01ksj.htm',
     'æ¸…éœç¶“': 'sj03qjj.htm',
     'ä¸­ç§‹æœˆ': 'sx08zqy.htm',
     'ç§‹æ±Ÿå¤œæ³Š': 'sx09qjyb.htm',
     'è‰¯å®µå¼•': 'sx15lxy.htm',
     'é›è½å¹³æ²™': 'ylps.htm',
     'æ¢…èŠ±': 'hw20mh.htm',
     'ç§‹é¢¨è¾­': 'hw07qfc.htm',
     'æ¸…å¹³æ¨‚': 'hw02qpy.htm',
     'é³³å‡°è‡ºä¸Šæ†¶å¹ç°«': 'hw15fhts.htm',
     'ç›¸æ€æ›²': 'cx38xsq.htm#lyrics',
     'æ¼æ¨µå•ç­”': 'yqwd.htm',
     'é™Œä¸Šæ¡‘': 'lq12mss.htm',
     'é·—é·ºå¿˜æ©Ÿ': 'sz03olwj.htm',
     'è‰²ç©ºè¨£': 'ty28skj.htm',
     'æ¢§è‘‰èˆç§‹é¢¨': 'qx14wywq.htm',
     'è‡¨æ²³ä¿®ç¦Š': 'qx09lhxx.htm',
     'ç§‹é¢¨æ›²': '1709qfq.htm#1709muslyr',
     'ç§‹é¢¨è©': '1709qfq.htm#1840muslyr',
     'æ˜¥é–¨æ€¨': 'ylcx.htm#cgyfn'}




```py